---
title: "p8105_hw3_xh2395"
author: "Xin  He"
date: "10/12/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(p8105.datasets)
data("instacart")
data("brfss_smart2010")
library(ggridges)
```

## Problem 1
**How many aisles are there?**
```{r}
instacart%>%
  group_by(aisle) %>%
  summarize(n_of_aisle = n())
```
There are 134 aisels.

**Which aisles are the most items ordered from?**
```{r}
instacart%>%
  group_by(aisle) %>%
  summarize(n_of_aisle = n()) %>% 
  filter(min_rank(desc(n_of_aisle)) < 2)
```
The most items are ordered from fresh vegetables. The items in fresh vegetables are ordered 150609 times.

**Plot that shows the number of items ordered in each aisle**
```{r}
instacart%>%
  group_by(aisle) %>%
  summarize(n_of_aisle = n()) %>% 
  filter(n_of_aisle > 10000) %>% 
  ggplot(aes(x = aisle, y = n_of_aisle)) + 
  geom_bar(stat="identity") +
  theme(text = element_text(size=12),
         axis.text.x = element_text(angle=90, vjust=0.5)) +
  labs(
    title = "Aisles plot",
    x = "names of aisles",
    y = "number of items ordered in each aisle",
    caption = "Data from instacart")
```
In the plot, there are 39 aisles that are with more than 10000 items ordered. X asix is the names of different aisles. Y asix is the number of items ordered in each aisle,and 50000 is used as each break. 

**Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”**
```{r}
instacart%>%
  filter(aisle == c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle, product_name) %>%
  summarize(n_aisle_product = n()) %>% 
  filter(min_rank(desc(n_aisle_product)) < 4) %>% 
  knitr::kable(digits = 0)
```

As shown in the table, in the aisle “baking ingredients”, the three most popular items are "Light Brown Sugar", "Organic Vanilla Extract" and "Pure Baking Soda"; in the aisle “dog food care”, the three most popular items are "Organix Chicken & Brown Rice Recipe", "Organix Grain Free Chicken & Vegetable Dog Food" and "Original Dry Dog"; in the aisle “packaged vegetables fruits”, the three most popular items are "Organic Baby Spinach", "Organic Blueberries" and "Organic Raspberries".

**Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week**
```{r}
instacart%>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name,order_dow) %>%
  summarize(mean_order_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_order_hour) %>% 
  rename(Sunday = "0", Monday = "1", Tuesday = "2", Wednesday = "3", Thursday = "4", Friday = "5", Saturday = "6") %>% 
  knitr::kable(digits = 1)
```

As shown in the table, the mean order hour of Coffee Ice Cream on Tuesday is the latest (15.4) and the mean order hour of Pink Lady Apples on Wednesday is the latest (14.2).

The dataset, "instacart", has `r nrow(instacart)` observations and `r ncol(instacart)` columns. Key variables include order_dow, order_hour_of_day, product_name and aisle.
Ice cream is ordered later than apples.


## Problem 2
**data cleaning**
```{r}
brfss_clean = 
  brfss_smart2010 %>% 
  janitor::clean_names() %>%
  rename(state = "locationabbr", location = "locationdesc") %>% 
  filter(topic == "Overall Health") %>%  
  filter(response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) %>%
  mutate(response = as.factor(response),
         response = forcats::fct_relevel(response, c("Poor","Fair","Good", "Very good","Excellent")))
```

**In 2002, which states were observed at 7 or more locations?**
```{r}
brfss_clean%>%
  filter(year == 2002) %>%
  group_by(state) %>%
  summarize(n_location = n_distinct(location, na.rm = FALSE)) %>%
  filter(n_location >= 7) %>% 
  knitr::kable()
```

According to the table, in 2002, CT, FL, MA, NC, NJ and PA were observed at 7 or more locations.

**In 2010, which states were observed at 7 or more locations?**
```{r}
brfss_clean%>%
  filter(year == 2010) %>%
  group_by(state) %>%
  summarize(n_location = n_distinct(location, na.rm = FALSE)) %>%
  filter(n_location >= 7) %>% 
  knitr::kable()
```

According to the table, in 2010, CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC, TX and WA were observed at 7 or more locations.

**Construct a NEW dataset**
```{r}
brfss_new = 
  filter(brfss_clean, response == "Excellent") %>% 
  group_by(year,state) %>%
  mutate(mean_data_value = mean(data_value, na.rm = FALSE)) %>% 
  select(year, state, mean_data_value) %>% 
  distinct()
```

**Plot about average value over time within a state**
```{r}
brfss_new %>% 
  ggplot(aes(x = year, y = mean_data_value, color = state)) +
  geom_line() +
  labs(
    title = "Average value over time within a state",
    x = "Year",
    y = "Mean value")
```

According to the plot, X asix is year (2002-2010). Y asix is the mean value. The plot shows the change of average value over time within different states.

**two-panel plot**
```{r}
brfss_clean %>% 
  filter(state == "NY", year %in% c(2006, 2010)) %>% 
  ggplot(aes(x = response, y = data_value, color = response)) +
  geom_boxplot() +
  facet_grid(. ~ year) +
  theme(text = element_text(size=12),
         axis.text.x = element_text(angle=90, vjust=0.5)) +
  labs(
    title = "Distribution of data_value for responses among locations in NY State",
    x = "Response",
    y = "data_value")
```

The plot shows the distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State for the year 2006 and 2010. 
The left panel is year 2006 and the right panel is year 2010. X asix is response type. Y asix is the data_value.
In both 2006 and 2010, the data_value of "Very good" response is highest.


## Problem 3
**Load, tidy, and wrangle the data**
```{r}
accel_data = 
  read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>%
  mutate(
    type = case_when(
      day %in% c("Saturday", "Sunday") ~ "weekend",
      day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday") ~ "weekday",
      TRUE     ~ ""
  )) %>% 
  mutate(day = as.factor(day),
         day = forcats::fct_relevel(day, c("Sunday","Monday","Tuesday", "Wednesday","Thursday", "Friday", "Saturday"))) %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity",
    names_prefix = "activity_",
    values_to = "count")

mutate(accel_data, activity = as.numeric(activity))
```

The dataset, "accel_data", has `r nrow(accel_data)` observations and `r ncol(accel_data)` columns. Key variables include week, type, day activity and count.

**Create a total activity variable for each day**
```{r}
accel_data %>% 
  group_by(week,day, day_id) %>%
  summarize(activity_total = sum(count)) %>% 
  knitr::kable(digits = 0)
```

The table has 35 rows and 4 columns. It is ordered from week 1 to 5, from Sunday to Saturday.
However, I do not see apparent trend.

**Single-panel plot that shows the 24-hour activity time courses**
```{r}
accel_new = 
  accel_data %>% 
  group_by(week,day, day_id) %>%
  summarize(activity_total = sum(count))

accel_new <- tibble::rowid_to_column(accel_new, "ID")

accel_new %>%
    ggplot(aes(x = ID, y = activity_total)) +
    geom_point(aes(color = day), alpha = .5) +
    geom_smooth(se = FALSE)
```

According to the plot, X asix is date by sequence in 5 weeks. Y asix is the total activity for each day. 7 colors represent different days. The blue line represents the trend of change of total activity every day. We can see that following the real-day sequence, the daily total activity goes up during the first 15 days, and then goes down during the 15th to 25th day, and goes up again during the last 10 days.









