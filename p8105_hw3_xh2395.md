p8105\_hw3\_xh2395
================
Xin He
10/12/2019

## Problem 1

**How many aisles are there?**

``` r
instacart%>%
  group_by(aisle) %>%
  summarize(n_of_aisle = n())
```

    ## # A tibble: 134 x 2
    ##    aisle                  n_of_aisle
    ##    <chr>                       <int>
    ##  1 air fresheners candles       1067
    ##  2 asian foods                  7007
    ##  3 baby accessories              306
    ##  4 baby bath body care           328
    ##  5 baby food formula           13198
    ##  6 bakery desserts              1501
    ##  7 baking ingredients          13088
    ##  8 baking supplies decor        1094
    ##  9 beauty                        287
    ## 10 beers coolers                1839
    ## # … with 124 more rows

There are 134 aisels.

**Which aisles are the most items ordered from?**

``` r
instacart%>%
  group_by(aisle) %>%
  summarize(n_of_aisle = n()) %>% 
  filter(min_rank(desc(n_of_aisle)) < 2)
```

    ## # A tibble: 1 x 2
    ##   aisle            n_of_aisle
    ##   <chr>                 <int>
    ## 1 fresh vegetables     150609

The most items are ordered from fresh vegetables. The items in fresh
vegetables are ordered 150609 times.

**Plot that shows the number of items ordered in each aisle**

``` r
instacart%>%
  group_by(aisle) %>%
  summarize(n_of_aisle = n()) %>% 
  filter(n_of_aisle > 10000) %>% 
  ggplot(aes(x = aisle, y = n_of_aisle)) + 
  geom_bar(stat="identity") +
  theme(text = element_text(size=12),
         axis.text.x = element_text(angle=90, vjust=0.5)) +
  labs(
    title = "Aisles plot",
    x = "names of aisles",
    y = "number of items ordered in each aisle",
    caption = "Data from instacart")
```

![](p8105_hw3_xh2395_files/figure-gfm/unnamed-chunk-3-1.png)<!-- --> In
the plot, there are 39 aisles that are with more than 10000 items
ordered. X asix is the names of different aisles. Y asix is the number
of items ordered in each aisle,and 50000 is used as each break.

**Make a table showing the three most popular items in each of the
aisles “baking ingredients”, “dog food care”, and “packaged vegetables
fruits”**

``` r
instacart%>%
  filter(aisle == c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle, product_name) %>%
  summarize(n_aisle_product = n()) %>% 
  filter(min_rank(desc(n_aisle_product)) < 4) %>% 
  knitr::kable(digits = 0)
```

| aisle                      | product\_name                                   | n\_aisle\_product |
| :------------------------- | :---------------------------------------------- | ----------------: |
| baking ingredients         | Light Brown Sugar                               |               157 |
| baking ingredients         | Organic Vanilla Extract                         |               122 |
| baking ingredients         | Pure Baking Soda                                |               140 |
| dog food care              | Organix Chicken & Brown Rice Recipe             |                13 |
| dog food care              | Organix Grain Free Chicken & Vegetable Dog Food |                14 |
| dog food care              | Original Dry Dog                                |                 9 |
| packaged vegetables fruits | Organic Baby Spinach                            |              3324 |
| packaged vegetables fruits | Organic Blueberries                             |              1692 |
| packaged vegetables fruits | Organic Raspberries                             |              1920 |

As shown in the table, in the aisle “baking ingredients”, the three most
popular items are “Light Brown Sugar”, “Organic Vanilla Extract” and
“Pure Baking Soda”; in the aisle “dog food care”, the three most
popular items are “Organix Chicken & Brown Rice Recipe”, “Organix Grain
Free Chicken & Vegetable Dog Food” and “Original Dry Dog”; in the aisle
“packaged vegetables fruits”, the three most popular items are
“Organic Baby Spinach”, “Organic Blueberries” and “Organic
Raspberries”.

**Make a table showing the mean hour of the day at which Pink Lady
Apples and Coffee Ice Cream are ordered on each day of the week**

``` r
instacart%>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name,order_dow) %>%
  summarize(mean_order_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_order_hour) %>% 
  rename(Sunday = "0", Monday = "1", Tuesday = "2", Wednesday = "3", Thursday = "4", Friday = "5", Saturday = "6") %>% 
  knitr::kable(digits = 1)
```

| product\_name    | Sunday | Monday | Tuesday | Wednesday | Thursday | Friday | Saturday |
| :--------------- | -----: | -----: | ------: | --------: | -------: | -----: | -------: |
| Coffee Ice Cream |   13.8 |   14.3 |    15.4 |      15.3 |     15.2 |   12.3 |     13.8 |
| Pink Lady Apples |   13.4 |   11.4 |    11.7 |      14.2 |     11.6 |   12.8 |     11.9 |

As shown in the table, the mean order hour of Coffee Ice Cream on
Tuesday is the latest (15.4) and the mean order hour of Pink Lady Apples
on Wednesday is the latest (14.2).

The dataset, “instacart”, has 1384617 observations and 15 columns. Key
variables include order\_dow, order\_hour\_of\_day, product\_name and
aisle. Ice cream is ordered later than apples.

## Problem 2

**data cleaning**

``` r
brfss_clean = 
  brfss_smart2010 %>% 
  janitor::clean_names() %>%
  rename(state = "locationabbr", location = "locationdesc") %>% 
  filter(topic == "Overall Health") %>%  
  filter(response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) %>%
  mutate(response = as.factor(response),
         response = forcats::fct_relevel(response, c("Poor","Fair","Good", "Very good","Excellent")))
```

**In 2002, which states were observed at 7 or more locations?**

``` r
brfss_clean%>%
  filter(year == 2002) %>%
  group_by(state) %>%
  summarize(n_location = n_distinct(location, na.rm = FALSE)) %>%
  filter(n_location >= 7) %>% 
  knitr::kable()
```

| state | n\_location |
| :---- | ----------: |
| CT    |           7 |
| FL    |           7 |
| MA    |           8 |
| NC    |           7 |
| NJ    |           8 |
| PA    |          10 |

According to the table, in 2002, CT, FL, MA, NC, NJ and PA were observed
at 7 or more locations.

**In 2010, which states were observed at 7 or more locations?**

``` r
brfss_clean%>%
  filter(year == 2010) %>%
  group_by(state) %>%
  summarize(n_location = n_distinct(location, na.rm = FALSE)) %>%
  filter(n_location >= 7) %>% 
  knitr::kable()
```

| state | n\_location |
| :---- | ----------: |
| CA    |          12 |
| CO    |           7 |
| FL    |          41 |
| MA    |           9 |
| MD    |          12 |
| NC    |          12 |
| NE    |          10 |
| NJ    |          19 |
| NY    |           9 |
| OH    |           8 |
| PA    |           7 |
| SC    |           7 |
| TX    |          16 |
| WA    |          10 |

According to the table, in 2010, CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH,
PA, SC, TX and WA were observed at 7 or more locations.

**Construct a NEW dataset**

``` r
brfss_new = 
  filter(brfss_clean, response == "Excellent") %>% 
  group_by(year,state) %>%
  mutate(mean_data_value = mean(data_value, na.rm = FALSE)) %>% 
  select(year, state, mean_data_value) %>% 
  distinct()
```

**Plot about average value over time within a state**

``` r
brfss_new %>% 
  ggplot(aes(x = year, y = mean_data_value, color = state)) +
  geom_line() +
  labs(
    title = "Average value over time within a state",
    x = "Year",
    y = "Mean value")
```

    ## Warning: Removed 3 rows containing missing values (geom_path).

![](p8105_hw3_xh2395_files/figure-gfm/unnamed-chunk-10-1.png)<!-- -->

According to the plot, X asix is year (2002-2010). Y asix is the mean
value. The plot shows the change of average value over time within
different states.

**two-panel plot**

``` r
brfss_clean %>% 
  filter(state == "NY", year %in% c(2006, 2010)) %>% 
  ggplot(aes(x = response, y = data_value, color = response)) +
  geom_boxplot() +
  facet_grid(. ~ year) +
  theme(text = element_text(size=12),
         axis.text.x = element_text(angle=90, vjust=0.5)) +
  labs(
    title = "Distribution of data_value for responses among locations in NY State",
    x = "Response",
    y = "data_value")
```

![](p8105_hw3_xh2395_files/figure-gfm/unnamed-chunk-11-1.png)<!-- -->

The plot shows the distribution of data\_value for responses (“Poor” to
“Excellent”) among locations in NY State for the year 2006 and 2010.
The left panel is year 2006 and the right panel is year 2010. X asix is
response type. Y asix is the data\_value. In both 2006 and 2010, the
data\_value of “Very good” response is highest.

## Problem 3

**Load, tidy, and wrangle the data**

``` r
accel_data = 
  read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>%
  mutate(
    type = case_when(
      day %in% c("Saturday", "Sunday") ~ "weekend",
      day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday") ~ "weekday",
      TRUE     ~ ""
  )) %>% 
  mutate(day = as.factor(day),
         day = forcats::fct_relevel(day, c("Sunday","Monday","Tuesday", "Wednesday","Thursday", "Friday", "Saturday"))) %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity",
    names_prefix = "activity_",
    values_to = "count")
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double(),
    ##   day = col_character()
    ## )

    ## See spec(...) for full column specifications.

``` r
mutate(accel_data, activity = as.numeric(activity))
```

    ## # A tibble: 50,400 x 6
    ##     week day_id day    type    activity count
    ##    <dbl>  <dbl> <fct>  <chr>      <dbl> <dbl>
    ##  1     1      1 Friday weekday        1  88.4
    ##  2     1      1 Friday weekday        2  82.2
    ##  3     1      1 Friday weekday        3  64.4
    ##  4     1      1 Friday weekday        4  70.0
    ##  5     1      1 Friday weekday        5  75.0
    ##  6     1      1 Friday weekday        6  66.3
    ##  7     1      1 Friday weekday        7  53.8
    ##  8     1      1 Friday weekday        8  47.8
    ##  9     1      1 Friday weekday        9  55.5
    ## 10     1      1 Friday weekday       10  43.0
    ## # … with 50,390 more rows

The dataset, “accel\_data”, has 50400 observations and 6 columns. Key
variables include week, type, day activity and count.

**Create a total activity variable for each day**

``` r
accel_data %>% 
  group_by(week,day, day_id) %>%
  summarize(activity_total = sum(count)) %>% 
  knitr::kable(digits = 0)
```

| week | day       | day\_id | activity\_total |
| ---: | :-------- | ------: | --------------: |
|    1 | Sunday    |       4 |          631105 |
|    1 | Monday    |       2 |           78828 |
|    1 | Tuesday   |       6 |          307094 |
|    1 | Wednesday |       7 |          340115 |
|    1 | Thursday  |       5 |          355924 |
|    1 | Friday    |       1 |          480543 |
|    1 | Saturday  |       3 |          376254 |
|    2 | Sunday    |      11 |          422018 |
|    2 | Monday    |       9 |          295431 |
|    2 | Tuesday   |      13 |          423245 |
|    2 | Wednesday |      14 |          440962 |
|    2 | Thursday  |      12 |          474048 |
|    2 | Friday    |       8 |          568839 |
|    2 | Saturday  |      10 |          607175 |
|    3 | Sunday    |      18 |          467052 |
|    3 | Monday    |      16 |          685910 |
|    3 | Tuesday   |      20 |          381507 |
|    3 | Wednesday |      21 |          468869 |
|    3 | Thursday  |      19 |          371230 |
|    3 | Friday    |      15 |          467420 |
|    3 | Saturday  |      17 |          382928 |
|    4 | Sunday    |      25 |          260617 |
|    4 | Monday    |      23 |          409450 |
|    4 | Tuesday   |      27 |          319568 |
|    4 | Wednesday |      28 |          434460 |
|    4 | Thursday  |      26 |          340291 |
|    4 | Friday    |      22 |          154049 |
|    4 | Saturday  |      24 |            1440 |
|    5 | Sunday    |      32 |          138421 |
|    5 | Monday    |      30 |          389080 |
|    5 | Tuesday   |      34 |          367824 |
|    5 | Wednesday |      35 |          445366 |
|    5 | Thursday  |      33 |          549658 |
|    5 | Friday    |      29 |          620860 |
|    5 | Saturday  |      31 |            1440 |

The table has 35 rows and 4 columns. It is ordered from week 1 to 5,
from Sunday to Saturday. However, I do not see apparent trend.

**Single-panel plot that shows the 24-hour activity time courses**

``` r
accel_new = 
  accel_data %>% 
  group_by(week,day, day_id) %>%
  summarize(activity_total = sum(count))

accel_new <- tibble::rowid_to_column(accel_new, "ID")

accel_new %>%
    ggplot(aes(x = ID, y = activity_total)) +
    geom_point(aes(color = day), alpha = .5) +
    geom_smooth(se = FALSE)
```

    ## `geom_smooth()` using method = 'loess' and formula 'y ~ x'

![](p8105_hw3_xh2395_files/figure-gfm/unnamed-chunk-14-1.png)<!-- -->

According to the plot, X asix is date by sequence in 5 weeks. Y asix is
the total activity for each day. 7 colors represent different days. The
blue line represents the trend of change of total activity every day. We
can see that following the real-day sequence, the daily total activity
goes up during the first 15 days, and then goes down during the 15th to
25th day, and goes up again during the last 10 days.
